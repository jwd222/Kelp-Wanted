{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install catboost\n",
    "# ! pip install seaborn\n",
    "# ! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# ---------------------------------------------------\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# from featexp import get_univariate_plots\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# -------------------------data-----------------------#\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Required libraries\n",
    "import tifffile as tiff\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import Window\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.transform import Affine\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the input GeoTIFF file\n",
    "input_file = r\"D:\\projects\\kelp_wanted\\data\\train_satellite\\AA498489_satellite.tif\"\n",
    "mask_file = r\"D:\\projects\\kelp_wanted\\data\\train_kelp\\AA498489_kelp.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_satellite_path = r\"D:\\projects\\kelp_wanted\\data\\train_satellite\"\n",
    "train_label_path = r\"D:\\projects\\kelp_wanted\\data\\train_kelp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of train files\n",
    "train_input = os.listdir(train_satellite_path)\n",
    "train_input_id = [d.split(\"_\")[0] for d in train_input if d.endswith(\".tif\")]\n",
    "\n",
    "# Get the list of train labels\n",
    "train_label = os.listdir(train_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scale factor and offset\n",
    "scale_factor = 0.0000275\n",
    "offset = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a dataframe with column for 7 bands, label and id\n",
    "# df = pd.DataFrame(columns=[\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"label\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []  # Initialize list to store DataFrames\n",
    "# count = 0\n",
    "\n",
    "# Loop over each file\n",
    "for file in tqdm(train_input_id):  # Adjust the range as needed\n",
    "    # Read the GeoTIFF file\n",
    "    with rasterio.open(train_satellite_path + \"\\\\\" + file + \"_satellite.tif\") as src:\n",
    "        # Read all bands\n",
    "        band_data = src.read().astype(np.float32)  # Convert to float32\n",
    "        # Get the shape of the image\n",
    "        height, width = src.height, src.width\n",
    "        # Apply scale factor and offset to all bands except band 6 and band 7\n",
    "        for i in range(7):\n",
    "            if i != 5 and i != 6:  # Skip band 6 and band 7\n",
    "                band_data[i] = band_data[i] * scale_factor + offset\n",
    "\n",
    "        # Create a mask where band 7 values are greater than 0\n",
    "        land_mask = band_data[6] > 0\n",
    "        # Apply the land mask to all bands except band 6 and 7\n",
    "        for i in range(5):\n",
    "            band_data[i][land_mask] = 0\n",
    "\n",
    "        # Find the indices of pixels not in the land mask\n",
    "        non_land_mask_indices = np.where(~land_mask)\n",
    "\n",
    "        # Read the binary mask TIFF file\n",
    "        with rasterio.open(train_label_path + \"\\\\\" + file + \"_kelp.tif\") as mask_src:\n",
    "            # Read the mask data\n",
    "            kelp_mask = mask_src.read(1)\n",
    "            # Find the locations where the mask values are 1\n",
    "            kelp_mask_indices = np.where(kelp_mask == 1)\n",
    "            \n",
    "        # \"\"\" Select all non land pixels\n",
    "        # Filter pixels with band 6 values greater than 0\n",
    "        selected_indices_filtered = (\n",
    "            non_land_mask_indices[0][band_data[5][non_land_mask_indices] == 0],\n",
    "            non_land_mask_indices[1][band_data[5][non_land_mask_indices] == 0],\n",
    "        )\n",
    "        # \"\"\"\n",
    "\n",
    "        '''# Select a random sample of pixels\n",
    "        num_random_samples = min(\n",
    "            len(non_land_mask_indices[0]), len(kelp_mask_indices[0]), 1000\n",
    "        )\n",
    "        random_indices = random.sample(\n",
    "            range(len(non_land_mask_indices[0])), num_random_samples\n",
    "        )\n",
    "        # Combine indices of kelp mask pixels and random sample pixels\n",
    "        selected_indices = (\n",
    "            np.concatenate(\n",
    "                (kelp_mask_indices[0], non_land_mask_indices[0][random_indices])\n",
    "            ),\n",
    "            np.concatenate(\n",
    "                (kelp_mask_indices[1], non_land_mask_indices[1][random_indices])\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Filter pixels with band 6 values greater than 0\n",
    "        selected_indices_filtered = (\n",
    "            selected_indices[0][band_data[5][selected_indices] == 0],\n",
    "            selected_indices[1][band_data[5][selected_indices] == 0],\n",
    "        )\n",
    "        # '''\n",
    "\n",
    "        # Extract band values for each selected pixel\n",
    "        pixel_values = band_data[\n",
    "            :, selected_indices_filtered[0], selected_indices_filtered[1]\n",
    "        ].T\n",
    "\n",
    "        # Create a DataFrame for the selected pixels\n",
    "        df = pd.DataFrame(pixel_values, columns=[f\"B0{i+1}\" for i in range(7)])\n",
    "\n",
    "        # Create an array of labels\n",
    "        labels = np.zeros(len(selected_indices_filtered[0]))\n",
    "        labels[: len(kelp_mask_indices[0])] = 1  # Set labels to 1 for kelp mask pixels\n",
    "        df[\"label\"] = labels\n",
    "        df[\"id\"] = file\n",
    "        # count = count + 1\n",
    "        # df[\"count\"] = count\n",
    "\n",
    "        # Append DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Shuffle the DataFrame rows\n",
    "# df_shuffled = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_shuffled = pd.DataFrame(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df_shuffled.label == 0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_data[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the GeoTIFF file\n",
    "# with rasterio.open(input_file) as src:\n",
    "#     # Read all bands\n",
    "#     band_data = src.read().astype(np.float32)  # Convert to float32\n",
    "#     # Get the shape of the image\n",
    "#     height, width = src.height, src.width\n",
    "#     # Apply scale factor and offset to all bands except band 6 and band 7\n",
    "#     for i in range(7):\n",
    "#         if i != 5 and i != 6:  # Skip band 6 and band 7\n",
    "#             band_data[i] = band_data[i] * scale_factor + offset\n",
    "            \n",
    "#     # Create a mask where band 6 values are greater than 0\n",
    "#     land_mask = band_data[6] > 0\n",
    "#     # Apply the land mask to all bands except band 6\n",
    "#     for i in range(7):\n",
    "#         band_data[i][land_mask] = 0\n",
    "\n",
    "#     # Find the indices of pixels not in the land mask\n",
    "#     non_land_mask_indices = np.where(~land_mask)\n",
    "    \n",
    "#     # Read the binary mask TIFF file\n",
    "#     with rasterio.open(mask_file) as mask_src:\n",
    "#         # Read the mask data\n",
    "#         kelp_mask = mask_src.read(1)\n",
    "#         # Find the locations where the mask values are 1\n",
    "#         kelp_mask_indices = np.where(kelp_mask == 1)\n",
    "\n",
    "#     # Select a random sample of pixels\n",
    "#     num_random_samples = min(\n",
    "#         len(non_land_mask_indices[0]), len(kelp_mask_indices[0]), 1000\n",
    "#     )\n",
    "#     random_indices = random.sample(\n",
    "#         range(len(non_land_mask_indices[0])), num_random_samples\n",
    "#     )\n",
    "#     # Combine indices of kelp mask pixels and random sample pixels\n",
    "#     selected_indices = (\n",
    "#         np.concatenate(\n",
    "#             (kelp_mask_indices[0], non_land_mask_indices[0][random_indices])\n",
    "#         ),\n",
    "#         np.concatenate(\n",
    "#             (kelp_mask_indices[1], non_land_mask_indices[1][random_indices])\n",
    "#         ),\n",
    "#     )\n",
    "\n",
    "#     # Create a dictionary to store band values for each selected pixel\n",
    "#     data_dict = {f\"B0{i+1}\": band_data[i][selected_indices] for i in range(7)}\n",
    "#     # Create an array of labels\n",
    "#     labels = np.zeros(len(selected_indices[0]))\n",
    "#     labels[:len(kelp_mask_indices[0])] = 1  # Set labels to 1 for kelp mask pixels\n",
    "    \n",
    "#     # Add labels as a new column to the DataFrame\n",
    "#     data_dict[\"label\"] = labels\n",
    "#     data_dict[\"id\"] = input_id\n",
    "\n",
    "#     # Create a DataFrame from the dictionary\n",
    "#     df = pd.DataFrame(data_dict)\n",
    "#     # Shuffle the DataFrame rows\n",
    "#     df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI\n",
    "# (N - R)/(N + R)\t\n",
    "df_shuffled[\"NDVI\"] = (df_shuffled[\"B02\"] - df_shuffled[\"B03\"]) / (\n",
    "    df_shuffled[\"B02\"] + df_shuffled[\"B03\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDWI\n",
    "# (N - S1) / (N + S1)\n",
    "df_shuffled[\"NDWI\"] = (df_shuffled[\"B02\"] - df_shuffled[\"B01\"]) / (\n",
    "    df_shuffled[\"B02\"] + df_shuffled[\"B01\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate G-NDVI\n",
    "# (N - G) / (N + G)\n",
    "df_shuffled[\"G-NDVI\"] = (df_shuffled[\"B02\"] - df_shuffled[\"B04\"]) / (\n",
    "    df_shuffled[\"B02\"] + df_shuffled[\"B04\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate GRVI \n",
    "# (N / G)\n",
    "df_shuffled[\"GRVI\"] = (df_shuffled[\"B02\"] / df_shuffled[\"B04\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TGI\tTriangular Greenness Index\t-(-0.5*((R-B)*(R-G)-(R-G)*(R-B)))\n",
    "# df_shuffled[\"TGI\"] = -(-0.5 * (\n",
    "#     (df_shuffled[\"B03\"] - df_shuffled[\"B05\"]) * (df_shuffled[\"B03\"] - df_shuffled[\"B04\"]) \n",
    "#     - \n",
    "#     (df_shuffled[\"B03\"] - df_shuffled[\"B04\"]) * (df_shuffled[\"B03\"] - df_shuffled[\"B05\"])\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TVI\tTriangular Vegetation Index\t0.5 * (120 * (N - G) - 200 * (R - G))\n",
    "df_shuffled[\"TVI\"] = 0.5 * (120 * (df_shuffled[\"B02\"] - df_shuffled[\"B04\"]) - 200 * (df_shuffled[\"B03\"] - df_shuffled[\"B04\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate NIRv\n",
    "# # ((N - R) / (N + R)) * N\n",
    "# df_shuffled[\"NIRv\"] = ((df_shuffled[\"B02\"] - df_shuffled[\"B03\"]) / (df_shuffled[\"B02\"] + df_shuffled[\"B03\"])) * df_shuffled[\"B03\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CIgreen(Chlorophyll Index Green)\n",
    "# # (N / G) - 1.0\n",
    "# df_shuffled[\"CIgreen\"] = (df_shuffled[\"B02\"] / df_shuffled[\"B04\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find count of label 1 and 0\n",
    "#     # label_counts = df_shuffled['label'].value_counts()\n",
    "\n",
    "\n",
    "#     # Path to save the filtered GeoTIFF file\n",
    "#     output_file = (\n",
    "#         r\"D:\\projects\\kelp_wanted\\data\\test_data\\AA498489_satellite_filtered.tif\"\n",
    "#     )\n",
    "\n",
    "#     # Calculate the new transformation matrix with a vertical flip\n",
    "#     transform = Affine(\n",
    "#         src.transform.a, 0, src.transform.c, 0, -src.transform.e, src.transform.f\n",
    "#     )\n",
    "\n",
    "#     # Write the filtered image to a new GeoTIFF file\n",
    "#     with rasterio.open(\n",
    "#         output_file,\n",
    "#         \"w\",\n",
    "#         driver=\"GTiff\",\n",
    "#         width=width,\n",
    "#         height=height,\n",
    "#         count=7,\n",
    "#         dtype=band_data.dtype,\n",
    "#         crs=src.crs,\n",
    "#         transform=transform,\n",
    "#     ) as dst:\n",
    "#         for i in range(7):\n",
    "#             dst.write(band_data[i], i + 1)\n",
    "\n",
    "# print(\"Filtered image saved as:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled.to_csv(r\"D:\\projects\\kelp_wanted\\data\\data_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df_shuffled.drop(\n",
    "    columns=[\"id\", \"label\", \"B06\", \"B07\"]\n",
    ")  # Features excluding 'id' and 'label' columns\n",
    "y = df_shuffled[\"label\"]  # Target variable\n",
    "\n",
    "# Specify groups based on the 'id' column\n",
    "groups = df_shuffled[\"id\"]\n",
    "\n",
    "# Initialize the GroupShuffleSplit with a specified test size\n",
    "group_splitter = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into train and test sets while preserving group membership\n",
    "train_idx, test_idx = next(group_splitter.split(X, y, groups=groups))\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    task_type=\"GPU\",\n",
    "    iterations=5000,\n",
    "    learning_rate=0.001,\n",
    "    random_strength=0.1,\n",
    "    depth=8,\n",
    "    loss_function=\"MultiClass\",\n",
    ")\n",
    "model.fit(X_train.fillna(0), y_train)\n",
    "\n",
    "# Define the file path where you want to save the model\n",
    "model_file_path = r\"D:\\projects\\kelp_wanted\\model\\catboost_model_4.bin\"\n",
    "# Save the model\n",
    "model.save_model(model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset (assuming it's already loaded into X and y)\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df_shuffled.drop(\n",
    "    columns=[\"id\", \"label\", \"B06\", \"B07\"]\n",
    ")  # Features excluding 'id' and 'label' columns\n",
    "y = df_shuffled[\"label\"]  # Target variable\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create CatBoost Pool objects for training and validation data\n",
    "train_pool = Pool(data=X_train, label=y_train)\n",
    "val_pool = Pool(data=X_val, label=y_val)\n",
    "\n",
    "# Initialize and train the CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    task_type=\"GPU\",\n",
    "    iterations=5000,\n",
    "    learning_rate=0.001,\n",
    "    random_strength=0.1,\n",
    "    depth=8,\n",
    "    loss_function=\"MultiClass\",\n",
    "    l2_leaf_reg=3,  # L2 regularization strength\n",
    "    subsample=0.8,  # Subsample ratio for training\n",
    "    verbose=100,  # Print every 100 iterations\n",
    ")\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,  # Use a validation set to monitor performance\n",
    "    early_stopping_rounds=100,  # Stop training if the performance doesn't improve for 100 iterations\n",
    "    plot=True,  # Plot the training metrics during training\n",
    ")\n",
    "\n",
    "# Get predictions on the validation set\n",
    "val_preds = model.predict(X_val)\n",
    "\n",
    "# Evaluate accuracy\n",
    "val_accuracy = accuracy_score(y_val, val_preds)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = model.get_feature_importance(train_pool)\n",
    "print(\"Feature Importance:\", feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 5 path\n",
    "model_v5_path = r\"D:\\projects\\kelp_wanted\\model\\catboost_model_5_new_method.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_v5 = CatBoostClassifier()\n",
    "model_v5.load_model(model_v5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "preds = loaded_model.predict_proba(X_test.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predicted probabilities to class predictions\n",
    "threshold = 0.95  # Adjust threshold as needed\n",
    "pred_labels = (preds[:, 1] > threshold).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, pred_labels)\n",
    "\n",
    "# Compute total number of samples\n",
    "total_samples = len(y_test)\n",
    "\n",
    "# Convert confusion matrix to percentage values\n",
    "conf_matrix_percentage = (conf_matrix / total_samples) * 100\n",
    "\n",
    "print(\"Confusion Matrix (Percentage):\")\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, pred_labels)\n",
    "\n",
    "# Compute precision\n",
    "precision = precision_score(y_test, pred_labels)\n",
    "\n",
    "# Compute recall\n",
    "recall = recall_score(y_test, pred_labels)\n",
    "\n",
    "# Compute F1-score\n",
    "f1 = f1_score(y_test, pred_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, pred_labels)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_bands(df):\n",
    "#     # Calculate NDVI\n",
    "#     # (N - R)/(N + R)\n",
    "#     df[\"NDVI\"] = (df[\"B02\"] - df[\"B03\"]) / (\n",
    "#         df[\"B02\"] + df[\"B03\"]\n",
    "#     )\n",
    "#     # Calculate NDWI\n",
    "#     # (N - S1) / (N + S1)\n",
    "#     df[\"NDWI\"] = (df[\"B02\"] - df[\"B01\"]) / (\n",
    "#         df[\"B02\"] + df[\"B01\"]\n",
    "#     )\n",
    "#     # Calculate G-NDVI\n",
    "#     # (N - G) / (N + G)\n",
    "#     df[\"G-NDVI\"] = (df[\"B02\"] - df[\"B04\"]) / (\n",
    "#         df[\"B02\"] + df[\"B04\"]\n",
    "#     )\n",
    "#     # Calculate GRVI\n",
    "#     # (N / G)\n",
    "#     df[\"GRVI\"] = df[\"B02\"] / df[\"B04\"]\n",
    "#     # # TGI\tTriangular Greenness Index\t-(-0.5*((R-B)*(R-G)-(R-G)*(R-B)))\n",
    "#     # df[\"TGI\"] = -(-0.5 * (\n",
    "#     #     (df[\"B03\"] - df[\"B05\"]) * (df[\"B03\"] - df[\"B04\"])\n",
    "#     #     -\n",
    "#     #     (df[\"B03\"] - df[\"B04\"]) * (df[\"B03\"] - df[\"B05\"])\n",
    "#     #     )\n",
    "#     # )\n",
    "#     # TVI\tTriangular Vegetation Index\t0.5 * (120 * (N - G) - 200 * (R - G))\n",
    "#     df[\"TVI\"] = 0.5 * (\n",
    "#         120 * (df[\"B02\"] - df[\"B04\"])\n",
    "#         - 200 * (df[\"B03\"] - df[\"B04\"])\n",
    "#     )\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_satellite_path = r\"D:\\projects\\kelp_wanted\\data\\test_satellite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of train files\n",
    "test_satellite = os.listdir(test_satellite_path)\n",
    "test_satellite_id = [d.split(\"_\")[0] for d in test_satellite if d.endswith(\".tif\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_satellite_id[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(test_satellite_id):\n",
    "    # Read the id_kelp.tif file\n",
    "    with rasterio.open(test_satellite_path + \"\\\\\" + file + \"_satellite.tif\") as kelp_src:\n",
    "        # with rasterio.open(test_file) as kelp_src:\n",
    "        kelp_mask = kelp_src.read(1)\n",
    "        band_data = kelp_src.read().astype(np.float32)  # Convert to float32\n",
    "\n",
    "    # Create a zero image of the same dimension\n",
    "    zero_image = np.zeros_like(kelp_mask)\n",
    "\n",
    "    # \"\"\"\n",
    "    # Read all bands\n",
    "    # Get the shape of the image\n",
    "    height, width = kelp_src.height, kelp_src.width\n",
    "    # Apply scale factor and offset to all bands except band 6 and band 7\n",
    "    for i in range(5):\n",
    "        band_data[i] = band_data[i] * scale_factor + offset\n",
    "\n",
    "    # Create a land mask\n",
    "    land_mask = band_data[6] > 0  # Assuming band 6 represents land\n",
    "    # \"\"\"\n",
    "    # Read non-land pixels from the input image\n",
    "    non_land_pixels = band_data[:, ~land_mask]\n",
    "\n",
    "    # Remember the positions of non-land pixels\n",
    "    non_land_indices = np.where(~land_mask)\n",
    "\n",
    "    # Extract band values for each selected pixel\n",
    "    pixel_values = band_data[:, non_land_indices[0], non_land_indices[1]].T\n",
    "\n",
    "    # Create a DataFrame for the selected pixels\n",
    "    df = pd.DataFrame(pixel_values, columns=[f\"B0{i+1}\" for i in range(7)])\n",
    "\n",
    "    # dfs.append(df)\n",
    "    # # Concatenate all DataFrames in the list\n",
    "    # test_final_df = pd.concat(df, ignore_index=True)\n",
    "    # Shuffle the DataFrame rows\n",
    "    # df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Calculate NDVI\n",
    "    # (N - R)/(N + R)\n",
    "    df[\"NDVI\"] = (df[\"B02\"] - df[\"B03\"]) / (\n",
    "        df[\"B02\"] + df[\"B03\"]\n",
    "    )\n",
    "    # Calculate NDWI\n",
    "    # (N - S1) / (N + S1)\n",
    "    df[\"NDWI\"] = (df[\"B02\"] - df[\"B01\"]) / (\n",
    "        df[\"B02\"] + df[\"B01\"]\n",
    "    )\n",
    "    # Calculate G-NDVI\n",
    "    # (N - G) / (N + G)\n",
    "    df[\"G-NDVI\"] = (df[\"B02\"] - df[\"B04\"]) / (\n",
    "        df[\"B02\"] + df[\"B04\"]\n",
    "    )\n",
    "    # Calculate GRVI\n",
    "    # (N / G)\n",
    "    df[\"GRVI\"] = df[\"B02\"] / df[\"B04\"]\n",
    "    # # TGI\tTriangular Greenness Index\t-(-0.5*((R-B)*(R-G)-(R-G)*(R-B)))\n",
    "    # df[\"TGI\"] = -(-0.5 * (\n",
    "    #     (df[\"B03\"] - df[\"B05\"]) * (df[\"B03\"] - df[\"B04\"])\n",
    "    #     -\n",
    "    #     (df[\"B03\"] - df[\"B04\"]) * (df[\"B03\"] - df[\"B05\"])\n",
    "    #     )\n",
    "    # )\n",
    "    # TVI\tTriangular Vegetation Index\t0.5 * (120 * (N - G) - 200 * (R - G))\n",
    "    df[\"TVI\"] = 0.5 * (\n",
    "        120 * (df[\"B02\"] - df[\"B04\"])\n",
    "        - 200 * (df[\"B03\"] - df[\"B04\"])\n",
    "    )\n",
    "\n",
    "    # new_df = calculate_bands(df)\n",
    "\n",
    "    df_shuffled = df.drop(columns=[\"B06\", \"B07\"])\n",
    "\n",
    "    # Get predicted probabilities\n",
    "    test_preds_v5 = model_v5.predict_proba(df_shuffled.fillna(0))\n",
    "\n",
    "    # Convert predicted probabilities to class predictions\n",
    "    threshold = 0.9  # Adjust threshold as needed\n",
    "    test_pred_labels = (test_preds_v5[:, 1] > threshold).astype(int)\n",
    "\n",
    "    # Plant predictions on the zero image\n",
    "    zero_image[non_land_indices] = test_pred_labels\n",
    "\n",
    "    # Generate the binary result\n",
    "    binary_result = np.where(zero_image > 0, 1, 0)\n",
    "\n",
    "    # Save res\n",
    "    # Write the binary image to a GeoTIFF file\n",
    "    output_binary_image = f\"D:\\\\projects\\\\kelp_wanted\\\\data\\\\test_tiff_data\\\\{file.split('_')[0]}_kelp.tif\"\n",
    "    # output_binary_image = (\n",
    "    #     r\"D:\\projects\\kelp_wanted\\data\\test_tiff_data\\JS569579_kelp_90.tif\"\n",
    "    # )\n",
    "\n",
    "    with rasterio.open(\n",
    "        output_binary_image,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,  # Single band\n",
    "        dtype=binary_result.dtype,\n",
    "        crs=kelp_src.crs,\n",
    "        # transform=src.transform,\n",
    "    ) as dst:\n",
    "        # Write the final binary image to the GeoTIFF file\n",
    "        dst.write(binary_result, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = r\"D:\\projects\\kelp_wanted\\data\\train_satellite\\JS569579_satellite.tif\"  \n",
    "\n",
    "# Read the id_kelp.tif file\n",
    "with rasterio.open(test_file) as kelp_src:\n",
    "    kelp_mask = kelp_src.read(1)\n",
    "    band_data = kelp_src.read().astype(np.float32)  # Convert to float32\n",
    "\n",
    "# Create a zero image of the same dimension\n",
    "zero_image = np.zeros_like(kelp_mask)\n",
    "\n",
    "# \"\"\"\n",
    "# Read all bands\n",
    "# Get the shape of the image\n",
    "height, width = kelp_src.height, kelp_src.width\n",
    "# Apply scale factor and offset to all bands except band 6 and band 7\n",
    "for i in range(5):\n",
    "    band_data[i] = band_data[i] * scale_factor + offset\n",
    "\n",
    "# Create a land mask\n",
    "land_mask = band_data[6] > 0  # Assuming band 6 represents land\n",
    "# \"\"\"\n",
    "# Read non-land pixels from the input image\n",
    "non_land_pixels = band_data[:, ~land_mask]\n",
    "\n",
    "# Remember the positions of non-land pixels\n",
    "non_land_indices = np.where(~land_mask)\n",
    "\n",
    "# Extract band values for each selected pixel\n",
    "pixel_values = band_data[:, non_land_indices[0], non_land_indices[1]].T\n",
    "\n",
    "# Create a DataFrame for the selected pixels\n",
    "df = pd.DataFrame(pixel_values, columns=[f\"B0{i+1}\" for i in range(7)])\n",
    "\n",
    "# dfs.append(df)\n",
    "\n",
    "# # Concatenate all DataFrames in the list\n",
    "# test_final_df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "# # Shuffle the DataFrame rows\n",
    "# test_df_shuffled = test_final_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI\n",
    "# (N - R)/(N + R)\n",
    "df[\"NDVI\"] = (df[\"B02\"] - df[\"B03\"]) / (\n",
    "    df[\"B02\"] + df[\"B03\"]\n",
    ")\n",
    "# Calculate NDWI\n",
    "# (N - S1) / (N + S1)\n",
    "df[\"NDWI\"] = (df[\"B02\"] - df[\"B01\"]) / (\n",
    "    df[\"B02\"] + df[\"B01\"]\n",
    ")\n",
    "# Calculate G-NDVI\n",
    "# (N - G) / (N + G)\n",
    "df[\"G-NDVI\"] = (df[\"B02\"] - df[\"B04\"]) / (\n",
    "    df[\"B02\"] + df[\"B04\"]\n",
    ")\n",
    "# Calculate GRVI\n",
    "# (N / G)\n",
    "df[\"GRVI\"] = df[\"B02\"] / df[\"B04\"]\n",
    "# # TGI\tTriangular Greenness Index\t-(-0.5*((R-B)*(R-G)-(R-G)*(R-B)))\n",
    "# df[\"TGI\"] = -(-0.5 * (\n",
    "#     (df[\"B03\"] - df[\"B05\"]) * (df[\"B03\"] - df[\"B04\"])\n",
    "#     -\n",
    "#     (df[\"B03\"] - df[\"B04\"]) * (df[\"B03\"] - df[\"B05\"])\n",
    "#     )\n",
    "# )\n",
    "# TVI\tTriangular Vegetation Index\t0.5 * (120 * (N - G) - 200 * (R - G))\n",
    "df[\"TVI\"] = 0.5 * (\n",
    "    120 * (df[\"B02\"] - df[\"B04\"])\n",
    "    - 200 * (df[\"B03\"] - df[\"B04\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "test_preds = model_v5.predict_proba(df)\n",
    "\n",
    "# Convert predicted probabilities to class predictions\n",
    "threshold = 0.97  # Adjust threshold as needed\n",
    "test_pred_labels = (test_preds[:, 1] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.where(test_pred_labels == 1))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plant predictions on the zero image\n",
    "zero_image[non_land_indices] = test_pred_labels\n",
    "\n",
    "# Generate the binary result\n",
    "binary_result = np.where(zero_image > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the binary image to a GeoTIFF file\n",
    "output_binary_image = r\"D:\\projects\\kelp_wanted\\data\\test_data\\JS569579_kelp_97_v5.tif\"\n",
    "\n",
    "# # Calculate the new transformation matrix with a vertical flip\n",
    "# transform = Affine(\n",
    "#     test_src.transform.a,\n",
    "#     0,\n",
    "#     test_src.transform.c,\n",
    "#     0,\n",
    "#     -test_src.transform.e,\n",
    "#     test_src.transform.f,\n",
    "# )\n",
    "\n",
    "with rasterio.open(\n",
    "    output_binary_image,\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=height,\n",
    "    width=width,\n",
    "    count=1,  # Single band\n",
    "    dtype=binary_result.dtype,\n",
    "    crs=src.crs,\n",
    "    # transform=src.transform,\n",
    ") as dst:\n",
    "    # Write the final binary image to the GeoTIFF file\n",
    "    dst.write(binary_result, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the GeoTIFF file\n",
    "# with rasterio.open(test_file) as test_src:\n",
    "#     # Read all bands\n",
    "#     band_data = test_src.read().astype(np.float32)  # Convert to float32\n",
    "#     # Get the shape of the image\n",
    "#     height, width = test_src.height, test_src.width\n",
    "#     # Apply scale factor and offset to all bands except band 6 and band 7\n",
    "#     for i in range(5):\n",
    "#         band_data[i] = band_data[i] * scale_factor + offset\n",
    "\n",
    "#     # Reshape each band's data to 1-dimensional array\n",
    "#     reshaped_bands = {f\"B0{i+1}\": band_data[i].ravel() for i in range(5)}\n",
    "\n",
    "#     # Create a DataFrame from the dictionary\n",
    "#     test_df = pd.DataFrame(reshaped_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get predicted probabilities\n",
    "# test_preds = model.predict_proba(test_df.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert predicted probabilities to class predictions\n",
    "# threshold = 0.5  # Adjust threshold as needed\n",
    "# test_pred_labels = (test_preds[:, 1] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# from rasterio.transform import from_origin\n",
    "# from rasterio.enums import Resampling\n",
    "# from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "# # Define output file path for the binary image\n",
    "# # output_binary_image = \"output_binary_image.tif\"\n",
    "# output_binary_image = (\n",
    "#     r\"D:\\projects\\kelp_wanted\\data\\test_data\\AF169120_res.tif\"\n",
    "# )\n",
    "\n",
    "# # Get spatial properties of the original GeoTIFF file\n",
    "# transform = test_src.transform\n",
    "# crs = test_src.crs\n",
    "# dtype = test_src.dtypes[0]\n",
    "\n",
    "# # Define pixel values for the two classes (0 and 1)\n",
    "# class_0_value = 0\n",
    "# class_1_value = 255  # Assuming 8-bit integer image\n",
    "\n",
    "# # Reshape the predicted labels to match the original image dimensions\n",
    "# test_pred_labels_reshaped = test_pred_labels.reshape(height, width)\n",
    "\n",
    "# # Calculate the new transformation matrix with a vertical flip\n",
    "# transform = Affine(\n",
    "#     test_src.transform.a, 0, test_src.transform.c, 0, -test_src.transform.e, test_src.transform.f\n",
    "# )\n",
    "\n",
    "# # Write the binary image\n",
    "# with rasterio.open(\n",
    "#     output_binary_image,\n",
    "#     \"w\",\n",
    "#     driver=\"GTiff\",\n",
    "#     height=height,\n",
    "#     width=width,\n",
    "#     count=1,  # Single band\n",
    "#     dtype=dtype,\n",
    "#     crs=crs,\n",
    "#     transform=transform,\n",
    "# ) as dst:\n",
    "#     # Write predicted labels to the binary image\n",
    "\n",
    "\n",
    "#     dst.write(test_pred_labels_reshaped.astype(dtype), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predicted probabilities to class predictions\n",
    "threshold = 0.5  # Adjust threshold as needed\n",
    "pred_labels = (preds[:, 1] > threshold).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, pred_labels)\n",
    "\n",
    "# Compute total number of samples\n",
    "total_samples = len(y_val)\n",
    "\n",
    "# Convert confusion matrix to percentage values\n",
    "conf_matrix_percentage = (conf_matrix / total_samples) * 100\n",
    "\n",
    "print(\"Confusion Matrix (Percentage):\")\n",
    "print(conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_val, pred_labels)\n",
    "\n",
    "# Compute precision\n",
    "precision = precision_score(y_val, pred_labels)\n",
    "\n",
    "# Compute recall\n",
    "recall = recall_score(y_val, pred_labels)\n",
    "\n",
    "# Compute F1-score\n",
    "f1 = f1_score(y_val, pred_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, pred_labels)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd_maskrcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
